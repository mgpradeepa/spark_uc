(inp.filter(_.startsWith("v")),1)
(Created,1)
(",1)
(inputFile),1)
(SparkContext(rdd),1)
(WordCountExample,1)
(transform,1)
(println("input,1)
(outputFile,1)
(on,1)
(line,1)
(3/4/2016.,1)
(Load,1)
(y,1)
(},4)
(home/ubuntu/input/words.count/Mgpspark-1.4-SQL-and-DataFrames.txt,1)
(*/,1)
(word,2)
(args(0):/,1)
(org.apache.spark.SparkContext,1)
(sparkcontext,1)
(println(dat.filter(_.contains("var")).count(),1)
("var"),1)
(new,2)
(object,1)
(y),1)
(dat,1)
(1)).reduceByKey,1)
(println(s"output,1)
(=>,4)
(input,1)
(///,1)
(file,2)
(+,4)
(//,6)
(the,1)
(args(1),1)
(println(dat.filter(_.contains("val")).count(),1)
(=,9)
(words.map(word,1)
(up,1)
(pradeepm.gireesha,1)
(line.split("\\s+"),1)
((word,1)
(x,1)
(counts,1)
(dat.cache(),1)
(import,3)
(split,1)
(args(0),1)
(Array[String]),1)
(/home/ubuntu,1)
($outputFile"),1)
(sparkcontext.textFile(inputFile),1)
(/output/spark.save.file.output/<mgp6>,1)
(inputFile,1)
(counts.saveAsTextFile(outputFile),1)
(into,2)
(,110)
(org.apache.spark.SparkContext._,1)
(val,9)
(*,1)
(inp.flatMap,1)
(by,1)
(inp,1)
(cont.map(_.split("\\s+")(0)),1)
(main(args:,1)
(args(1):,1)
(count,1)
(/**,1)
(words,1)
(case,1)
(rdd,1)
(and,1)
({,4)
(println(counts.count()),1)
(SparkConf().setAppName("WordCountExample").setMaster("local"),1)
(def,1)
(cont,1)
((x,1)
(org.apache.spark.SparkConf,1)
("val"),1)
